{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "URL = \"https://www.indeed.com/jobs?q=web+developer&l=New+York\"\n",
    "page = requests.get(URL)\n",
    "print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "URL = \"https://www.indeed.com/jobs?q=web+developer&l=New+York\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find(id = \"resultsCol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_jobs = results.select(\"div.jobsearch-SerpJobCard.unifiedRow.row.result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for indeed_job in indeed_jobs:\n",
    "    job_title = indeed_job.find('h2', class_ = 'title')\n",
    "    job_company = indeed_job.find('span', class_ = 'company')\n",
    "    job_location = indeed_job.find('span', class_ = 'location accessible-contrast-color-location')\n",
    "    print(job_title.text.strip())\n",
    "    print(job_company.text.strip())\n",
    "    print(job_location.text.strip()) \n",
    "    \n",
    "job_url = indeed_job.find('a')['href']\n",
    "print(job_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract url\n",
    "#job_url = indeed_job.find('a')['href']\n",
    "#print(job_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data into a CSV file\n",
    "file = open(\"indeed-jobs.csv\", \"w\")\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['Title','Company','Location','Apply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML content\n",
    "#<h2 class = \"title is-5\"> Senior Python Developer </h2>\n",
    "#<h3 class = \"subtitle is-6 company\">Payne, Roberts and Davis</h3>\n",
    "#<p class = \"location\">Stewartbury, AA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_elem in job_element:\n",
    "    title_element = job_elem.find(\"h2\", class_ = \"Title\")\n",
    "    company_element = job_elem.find(\"h3\", class_ = \"Company\")\n",
    "    location_element = job_elem.find(\"p\", class_ = \"Location\")\n",
    "    print(title_element.text)\n",
    "    print(company_element.text)\n",
    "    print(location_element.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_elem in job_element:\n",
    "    title_element = job_elem.find(\"h2\", class_ = \"Title\")\n",
    "    company_element = job_elem.find(\"h3\", class_ = \"Company\")\n",
    "    location_element = job_elem.find(\"p\", class_ = \"Location\")\n",
    "    print(title_element.text.strip())\n",
    "    print(company_element.text.strip())\n",
    "    print(location_element.text.strip())\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the URL\n",
    "job_url = indeed_job.find('a')['href']\n",
    "print(job_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data into a CSV file\n",
    "file = open(\"indeed-jobs.csv\",\"w\")\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['Title','Company','Location','Apply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib.request\n",
    "#from urllib.request import urlopen,Request\n",
    "#from bs4 import BeautifulSoup\n",
    "#wiki = \"https://www.thestar.com.my/search/?q=HIV&qsort=oldest&qrec=10&qstockcode=&pgno=1\"\n",
    "#html=urlopen(wiki)\n",
    "#bs = BeautifulSoup(html, 'lxml')\n",
    "#bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bs4 import BeautifulSoup\n",
    "#base_url =\"https://www.thestar.com.my/search/?q=HIV&qsort=oldest&qrec=10&qstockcode=&pgno=\"\n",
    "#url_list = [\"{}{}\".format(base_url, str(page)) for page in range(1,408)]\n",
    "#s = []\n",
    "#for url_list:\n",
    "   # print(url)\n",
    "   # s.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import csv\n",
    "#from urllib.request import urlopen,HTTPError\n",
    "#from datetime import datetime,timedelta\n",
    "#for pg in s:\n",
    "   # page = urllib.request.urlopen(pg)\n",
    "#    try:\n",
    "#        search_response=urllib.request.urlopen(pg)\n",
    "#        except urllib.request.HTTPError:\n",
    "#            pass\n",
    "#        soup = BeautifulSoup(page,'html.parser')\n",
    "#        ls = [x.get_text(strip = True) for x in soup.find_all(\"h2\",{\"class\": \"f18\"})]\n",
    "#        ls1 = [x.get_text(strip = True) for x in soup.find_all(\"span\",{\"class\": \"date\"})]\n",
    "#        data.append((ls))\n",
    "#        data.append(ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = p.DataFrame(f,columns = ['Topic of article'])\n",
    "#df['Date'] = f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE OTHER CHUNK OF CODE (PART_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web_analysis = {'career Portal':'https://www.careersportal.co.za/',\n",
    "   #'careers 24':'https://www.careerjet.co.za/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for w,j in web_analysis.items():\n",
    "    #page = 0\n",
    "   # while True:\n",
    "       # time.sleep(1)\n",
    "        #r=requests.get(j, params = {\"page\":page+1})\n",
    "        #if 'No jobs were found that matched your search.'in r.text or r.status_code != 200:\n",
    "           # break\n",
    "       # else:\n",
    "           # html = r.content\n",
    "            #soup = BeautifulSoup(html,'lxml')\n",
    "            #print('\\033[1m' + '{0},page{1}'.format(w,page+1)+'\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
